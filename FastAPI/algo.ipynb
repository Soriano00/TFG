{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO acierta ninguno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases:\n",
      "NombreEjercicio\n",
      "Flexión             129\n",
      "Adducción           129\n",
      "Abducción           128\n",
      "Extensión           128\n",
      "Rotación externa    120\n",
      "Rotación interna    118\n",
      "Rotación Externa      1\n",
      "Rotación Interna      1\n",
      "Name: count, dtype: int64\n",
      "Cluster Centers: [[ 3.56826592 -0.33090601 -0.47285374 ... -0.61739465 -0.27939593\n",
      "  -0.06010442]\n",
      " [ 8.66995307  8.58074875 -8.58818537 ... -0.11808309 -0.11390114\n",
      "   0.10849708]\n",
      " [ 9.56895063 -8.36723863  8.32942177 ... -0.10763609  0.07849424\n",
      "  -0.09055917]\n",
      " [ 8.31305911  8.93066712  8.85528462 ... -0.12154862 -0.11460121\n",
      "  -0.10082801]\n",
      " [ 3.09753883  2.41517869 -0.01924332 ... -0.15924442 -0.1371667\n",
      "   0.01223987]\n",
      " [ 1.53150808  1.74970158 -0.13170167 ... -0.42376858 -0.34789658\n",
      "   0.05208021]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Conexión a la base de datos\n",
    "def connect_to_db(connection_string):\n",
    "    engine = create_engine(connection_string)\n",
    "    return engine\n",
    "\n",
    "# Cargar datos de las tablas de la base de datos\n",
    "def cargar_datos(engine):\n",
    "    ejercicios = pd.read_sql_table('Ejercicios', engine)\n",
    "    repeticiones = pd.read_sql_table('Repeticion', engine)\n",
    "    return ejercicios, repeticiones\n",
    "\n",
    "# Preprocesar los datos\n",
    "def preprocesar_datos(ejercicios, repeticiones):\n",
    "    data = repeticiones.merge(ejercicios, on='Id_ejercicio')\n",
    "    \n",
    "    # Seleccionar características relevantes y el objetivo\n",
    "    X = data[['Id_ejercicio', 'Num_Serie', 'Num_repeticion', 'Tiempo', 'Fuerza', 'Posicion', 'Velocidad', 'Trig']]\n",
    "    y = data['NombreEjercicio']\n",
    "\n",
    "    # Convertir características categóricas a numéricas si es necesario\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "\n",
    "    # Normalizar los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X, y, le, scaler\n",
    "\n",
    "# Transformar los datos para series temporales\n",
    "def transformar_datos(data):\n",
    "    grouped = data.groupby(['NombreEjercicio', 'Tiempo']).agg({\n",
    "        'Fuerza': list,\n",
    "        'Posicion': list,\n",
    "        'Velocidad': list\n",
    "    }).reset_index()\n",
    "    max_length = max(grouped['Fuerza'].apply(len))\n",
    "    X, y = [], []\n",
    "\n",
    "    for name, group in grouped.groupby('NombreEjercicio'):\n",
    "        series_fuerza = group['Fuerza'].apply(lambda x: np.pad(x, (0, max_length - len(x)), 'constant')).tolist()\n",
    "        series_posicion = group['Posicion'].apply(lambda x: np.pad(x, (0, max_length - len(x)), 'constant')).tolist()\n",
    "        series_velocidad = group['Velocidad'].apply(lambda x: np.pad(x, (0, max_length - len(x)), 'constant')).tolist()\n",
    "        \n",
    "        combined_series = [np.stack([f, p, v], axis=-1) for f, p, v in zip(series_fuerza, series_posicion, series_velocidad)]\n",
    "        X.extend(combined_series)\n",
    "        y.extend([name] * len(combined_series))\n",
    "    \n",
    "    X = np.array(X)\n",
    "    scaler = TimeSeriesScalerMeanVariance()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y\n",
    "\n",
    "# Entrenar el modelo\n",
    "def entrenar_modelo(X, y):\n",
    "    y = np.array(y)\n",
    "    X_flattened = X.reshape(X.shape[0], -1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flattened, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    \n",
    "    # Validación cruzada\n",
    "    scores = cross_val_score(clf, X_flattened, y, cv=5)\n",
    "    print(f\"Cross-validation scores: {scores}\")\n",
    "    print(f\"Mean cross-validation score: {scores.mean()}\")\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Revisión de predicciones en el conjunto de entrenamiento\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    print(\"Train Set Predictions:\", y_pred_train)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "# Aplicar clustering\n",
    "def aplicar_clustering(X, y):\n",
    "    num_clusters = len(np.unique(y))  # Usar el número de ejercicios como número de clusters\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    X_clustered = kmeans.fit_predict(X)\n",
    "    \n",
    "    # Análisis de clusters\n",
    "    print(\"Cluster Centers:\", kmeans.cluster_centers_)\n",
    "    \n",
    "    return kmeans, X_clustered\n",
    "\n",
    "# Predecir con nuevos datos\n",
    "def predecir(modelo, kmeans, datos_nuevos, max_length, scaler):\n",
    "    X = []\n",
    "    for tiempo, group in datos_nuevos.groupby('Tiempo'):\n",
    "        fuerzas = []\n",
    "        posiciones = []\n",
    "        velocidades = []\n",
    "        for f, p, v in zip(group['Fuerza'], group['Posicion'], group['Velocidad']):\n",
    "            if isinstance(f, list):\n",
    "                fuerzas.append(np.pad(f, (0, max_length - len(f)), 'constant'))\n",
    "                posiciones.append(np.pad(p, (0, max_length - len(p)), 'constant'))\n",
    "                velocidades.append(np.pad(v, (0, max_length - len(v)), 'constant'))\n",
    "            else:\n",
    "                fuerzas.append(np.pad([f], (0, max_length - 1), 'constant'))\n",
    "                posiciones.append(np.pad([p], (0, max_length - 1), 'constant'))\n",
    "                velocidades.append(np.pad([v], (0, max_length - 1), 'constant'))\n",
    "        \n",
    "        combined_series = np.stack([np.mean(fuerzas, axis=0), np.mean(posiciones, axis=0), np.mean(velocidades, axis=0)], axis=-1)\n",
    "        X.append(combined_series)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_flattened = X_scaled.reshape(X_scaled.shape[0], -1)\n",
    "\n",
    "    # Aplicar clustering a los nuevos datos\n",
    "    nuevos_datos_clustered = kmeans.predict(X_flattened)\n",
    "    X_flattened = np.hstack((X_flattened, nuevos_datos_clustered.reshape(-1, 1)))\n",
    "    \n",
    "    prediccion = modelo.predict(X_flattened)\n",
    "    \n",
    "    return prediccion\n",
    "\n",
    "# Ejecución del código\n",
    "if __name__ == \"__main__\":\n",
    "    engine = connect_to_db('mysql+pymysql://root:8963alex@localhost:3306/MyTrainer')\n",
    "    ejercicios, repeticiones = cargar_datos(engine)\n",
    "\n",
    "    # Verificar balance de clases\n",
    "    print(\"Distribución de clases:\")\n",
    "    print(ejercicios['NombreEjercicio'].value_counts())\n",
    "\n",
    "    X, y, le, scaler = preprocesar_datos(ejercicios, repeticiones)\n",
    "\n",
    "    if repeticiones.empty:\n",
    "        print(\"No hay datos disponibles después del preprocesamiento.\")\n",
    "    else:\n",
    "        X_series, y_series = transformar_datos(repeticiones.merge(ejercicios, on='Id_ejercicio'))\n",
    "\n",
    "        # Aplicar clustering a los datos de entrenamiento\n",
    "        kmeans, X_clustered = aplicar_clustering(X_series.reshape(X_series.shape[0], -1), y_series)\n",
    "        X_series_clustered = np.hstack((X_series.reshape(X_series.shape[0], -1), X_clustered.reshape(-1, 1)))\n",
    "\n",
    "        modelo = entrenar_modelo(X_series_clustered, y_series)\n",
    "\n",
    "        archivo_nuevos_datos = '040_Cin_RotIn_Dom.xlsx - Serie 1.csv'\n",
    "        nuevos_datos = pd.read_csv(archivo_nuevos_datos)\n",
    "        nuevos_datos.rename(columns={'Tiempo (s)': 'Tiempo', 'Fuerza (Kg)': 'Fuerza', 'Posición (cm)': 'Posicion', 'Velocidad (cm/s)': 'Velocidad'}, inplace=True)\n",
    "\n",
    "        max_length = X_series.shape[1]\n",
    "        scaler = TimeSeriesScalerMeanVariance()\n",
    "        scaler.fit(X_series)\n",
    "\n",
    "        prediccion = predecir(modelo, kmeans, nuevos_datos, max_length, scaler)\n",
    "        nombre_ejercicio_final = pd.Series(prediccion).mode()[0]\n",
    "\n",
    "        df_resultado = pd.DataFrame([nombre_ejercicio_final], columns=['NombreEjercicio'])\n",
    "        print(df_resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
