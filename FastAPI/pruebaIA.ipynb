{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10958/333903283.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  max_length = max(grouped.apply(lambda x: max(len(x['Fuerza']), len(x['Posicion']), len(x['Velocidad']))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       Abducción       0.24      0.15      0.19     22834\n",
      "       Extensión       0.24      0.15      0.19     24558\n",
      "         Flexión       0.22      0.14      0.17     23426\n",
      "Rotación externa       0.21      0.55      0.30     21163\n",
      "Rotación interna       0.19      0.11      0.14     20457\n",
      "\n",
      "        accuracy                           0.22    112438\n",
      "       macro avg       0.22      0.22      0.20    112438\n",
      "    weighted avg       0.22      0.22      0.20    112438\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions of the provided timeseries(except first) must match those of the fitted data! ((374793, 3, 94) and (671, 3, 3) are passed shapes)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 115\u001b[0m\n\u001b[1;32m    113\u001b[0m scaler \u001b[38;5;241m=\u001b[39m TimeSeriesScalerMeanVariance()\n\u001b[1;32m    114\u001b[0m scaler\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m--> 115\u001b[0m prediccion \u001b[38;5;241m=\u001b[39m \u001b[43mpredecir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnuevos_datos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicción final: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediccion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[20], line 82\u001b[0m, in \u001b[0;36mpredecir\u001b[0;34m(modelo, datos_nuevos, max_length, scaler)\u001b[0m\n\u001b[1;32m     79\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Escalar los nuevos datos utilizando el mismo scaler\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m X_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m X_flattened \u001b[38;5;241m=\u001b[39m X_scaled\u001b[38;5;241m.\u001b[39mreshape(X_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m prediccion \u001b[38;5;241m=\u001b[39m modelo\u001b[38;5;241m.\u001b[39mpredict(X_flattened)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tslearn/preprocessing/preprocessing.py:288\u001b[0m, in \u001b[0;36mTimeSeriesScalerMeanVariance.transform\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(X, allow_nd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m X_ \u001b[38;5;241m=\u001b[39m to_time_series_dataset(X)\n\u001b[0;32m--> 288\u001b[0m X_ \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_fit_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_X_fit_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m mean_t \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnanmean(X_, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    290\u001b[0m std_t \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mnanstd(X_, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tslearn/utils/utils.py:106\u001b[0m, in \u001b[0;36mcheck_dims\u001b[0;34m(X, X_fit_dims, extend, check_n_features_only)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m X_fit_dims[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m--> 106\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    107\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimensions of the provided timeseries\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(except first) must match those of the fitted data!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m are passed shapes)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(X_fit_dims, X\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    110\u001b[0m             )\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions of the provided timeseries(except first) must match those of the fitted data! ((374793, 3, 94) and (671, 3, 3) are passed shapes)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def connect_to_db(connection_string):\n",
    "    engine = create_engine(connection_string)\n",
    "    return engine\n",
    "\n",
    "def cargar_datos(engine):\n",
    "    ejercicios = pd.read_sql_table('Ejercicios', engine)\n",
    "    series = pd.read_sql_table('Serie', engine)\n",
    "    repeticiones = pd.read_sql_table('Repeticion', engine)\n",
    "    return ejercicios, series, repeticiones\n",
    "\n",
    "def preprocesar_datos(ejercicios, series, repeticiones):\n",
    "    data = repeticiones.merge(series, on=['Id_ejercicio', 'Num_Serie'])\n",
    "    data = data.merge(ejercicios, on='Id_ejercicio')\n",
    "    data = data[['NombreEjercicio', 'Tiempo', 'Fuerza', 'Posicion', 'Velocidad']]\n",
    "    data = data[data['NombreEjercicio'].isin(['Abducción', 'Aducción', 'Flexión', 'Extensión', 'Rotación interna', 'Rotación externa'])]\n",
    "    return data\n",
    "\n",
    "def transformar_datos(data):\n",
    "    grouped = data.groupby(['NombreEjercicio', 'Tiempo'])\n",
    "    max_length = max(grouped.apply(lambda x: max(len(x['Fuerza']), len(x['Posicion']), len(x['Velocidad']))))\n",
    "    \n",
    "    X, y = [], []\n",
    "    \n",
    "    for (name, tiempo), group in grouped:\n",
    "        # Convertir a listas de arrays numéricos si es necesario\n",
    "        fuerzas = group['Fuerza'].apply(lambda x: np.array(x) if isinstance(x, list) else np.array([x])).tolist()\n",
    "        posiciones = group['Posicion'].apply(lambda x: np.array(x) if isinstance(x, list) else np.array([x])).tolist()\n",
    "        velocidades = group['Velocidad'].apply(lambda x: np.array(x) if isinstance(x, list) else np.array([x])).tolist()\n",
    "        \n",
    "        # Aplicar padding si son listas de arrays\n",
    "        fuerzas = [np.pad(arr, (0, max_length - len(arr)), 'constant') for arr in fuerzas]\n",
    "        posiciones = [np.pad(arr, (0, max_length - len(arr)), 'constant') for arr in posiciones]\n",
    "        velocidades = [np.pad(arr, (0, max_length - len(arr)), 'constant') for arr in velocidades]\n",
    "        \n",
    "        X.extend(list(zip(fuerzas, posiciones, velocidades)))\n",
    "        y.extend([name] * len(fuerzas))\n",
    "    \n",
    "    X = np.array(X)\n",
    "    scaler = TimeSeriesScalerMeanVariance()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    return X_scaled, y\n",
    "\n",
    "def predecir(modelo, datos_nuevos, max_length, scaler):\n",
    "    X = []\n",
    "    for tiempo, group in datos_nuevos.groupby('Tiempo'):\n",
    "        fuerzas = []\n",
    "        posiciones = []\n",
    "        velocidades = []\n",
    "        \n",
    "        for f, p, v in zip(group['Fuerza'], group['Posicion'], group['Velocidad']):\n",
    "            if isinstance(f, list):\n",
    "                fuerzas.append(np.pad(f, (0, max_length - len(f)), 'constant'))\n",
    "            else:\n",
    "                fuerzas.append(np.pad([f], (0, max_length - 1), 'constant'))  # Convertir float a lista de un elemento\n",
    "        \n",
    "            if isinstance(p, list):\n",
    "                posiciones.append(np.pad(p, (0, max_length - len(p)), 'constant'))\n",
    "            else:\n",
    "                posiciones.append(np.pad([p], (0, max_length - 1), 'constant'))  # Convertir float a lista de un elemento\n",
    "        \n",
    "            if isinstance(v, list):\n",
    "                velocidades.append(np.pad(v, (0, max_length - len(v)), 'constant'))\n",
    "            else:\n",
    "                velocidades.append(np.pad([v], (0, max_length - 1), 'constant'))  # Convertir float a lista de un elemento\n",
    "        \n",
    "        # Calcular la media de cada serie temporal y añadir a X\n",
    "        X.append(np.mean(list(zip(fuerzas, posiciones, velocidades)), axis=0))\n",
    "    \n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Escalar los nuevos datos utilizando el mismo scaler\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_flattened = X_scaled.reshape(X_scaled.shape[0], -1)\n",
    "    \n",
    "    prediccion = modelo.predict(X_flattened)\n",
    "    \n",
    "    return prediccion\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Conexión a la base de datos\n",
    "    engine = connect_to_db('mysql+pymysql://root:8963alex@localhost:3306/MyTrainer')\n",
    "    \n",
    "    # 2. Cargar y preprocesar los datos\n",
    "    ejercicios, series, repeticiones = cargar_datos(engine)\n",
    "    datos_procesados = preprocesar_datos(ejercicios, series, repeticiones)\n",
    "    \n",
    "    # 3. Transformar los datos\n",
    "    X, y = transformar_datos(datos_procesados)\n",
    "    \n",
    "    # 4. Entrenar el modelo\n",
    "    modelo, kmeans = entrenar_modelo(X, y)\n",
    "    \n",
    "    # 5. Predicción con nuevos datos\n",
    "    archivo_nuevos_datos = '017_Cin_RotEx_Dom.xlsx - Serie 1.csv'  # Nombre del archivo con nuevos datos\n",
    "    nuevos_datos = pd.read_csv(archivo_nuevos_datos)\n",
    "    nuevos_datos.rename(columns={'Tiempo (s)': 'Tiempo', 'Fuerza (Kg)': 'Fuerza', 'Posición (cm)': 'Posicion', 'Velocidad (cm/s)': 'Velocidad'}, inplace=True)\n",
    "    \n",
    "    # Asegúrate de que los nombres de columnas sean los mismos que se esperan\n",
    "    if 'Tiempo' not in nuevos_datos.columns or 'Fuerza' not in nuevos_datos.columns or 'Posicion' not in nuevos_datos.columns or 'Velocidad' not in nuevos_datos.columns:\n",
    "        raise ValueError(\"Los nombres de las columnas en nuevos_datos no coinciden con lo esperado.\")\n",
    "    \n",
    "    max_length = X.shape[1]\n",
    "    scaler = TimeSeriesScalerMeanVariance()\n",
    "    scaler.fit(X)\n",
    "    prediccion = predecir(modelo, nuevos_datos, max_length, scaler)\n",
    "    print(f'Predicción final: {prediccion}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
