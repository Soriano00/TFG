{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este peta kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de df_scaled: (453429, 9)\n",
      "Total steps: 49990\n",
      "Step 0/49990\n",
      "Step 1000/49990\n",
      "Step 2000/49990\n",
      "Step 3000/49990\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Conectar a la base de datos MySQL\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://root:8963alex@localhost:3306/MyTrainer')\n",
    "\n",
    "# Obtener datos de ejercicios y repeticiones\n",
    "query_ejercicios = \"SELECT * FROM Ejercicios\"\n",
    "query_repeticiones = \"SELECT * FROM Repeticion\"\n",
    "\n",
    "# Guardar los datos de las tablas \n",
    "df_ejercicios = pd.read_sql(query_ejercicios, engine)\n",
    "df_repeticiones = pd.read_sql(query_repeticiones, engine)\n",
    "\n",
    "# Fusionar tablas para obtener nombres de ejercicios\n",
    "df = df_repeticiones.merge(df_ejercicios, on='Id_ejercicio', how='left')\n",
    "\n",
    "# Seleccionar características relevantes y el objetivo\n",
    "X = df[['Id_ejercicio', 'Num_Serie', 'Num_repeticion', 'Tiempo', 'Fuerza', 'Posicion', 'Velocidad', 'Trig']]\n",
    "y = df['NombreEjercicio']\n",
    "\n",
    "# Convertir características categóricas a numéricas si es necesario\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Ajustar el escalador a los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled_np = scaler.fit_transform(X)\n",
    "\n",
    "# Convertir los datos escalados de nuevo a DataFrame de pandas\n",
    "df_scaled = pd.DataFrame(X_scaled_np, columns=X.columns)\n",
    "\n",
    "# Convertir DataFrame a Dask DataFrame\n",
    "ddf_scaled = dd.from_pandas(df_scaled, npartitions=10)\n",
    "\n",
    "# Agregar la columna objetivo\n",
    "df_scaled['NombreEjercicio'] = y\n",
    "\n",
    "# Verificar dimensiones del DataFrame escalado\n",
    "print(f\"Dimensiones de df_scaled: {df_scaled.shape}\")\n",
    "\n",
    "# Crear ventanas deslizantes para series temporales\n",
    "def create_time_series(df, window_size, step):\n",
    "    X, y = [], []\n",
    "    total_steps = len(df) - window_size\n",
    "    print(f\"Total steps: {total_steps}\")\n",
    "    for i in range(0, total_steps, step):\n",
    "        X.append(df.iloc[i:i + window_size, :-1].values)\n",
    "        y.append(df.iloc[i + window_size - 1, -1])\n",
    "        if i % 1000 == 0:  # Imprimir el estado cada 1000 iteraciones\n",
    "            print(f\"Step {i}/{total_steps}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Definir tamaño de ventana y paso\n",
    "window_size = 10\n",
    "step = 1\n",
    "\n",
    "# Procesar datos en partes más pequeñas\n",
    "chunk_size = 50000  # Tamaño de cada chunk\n",
    "num_chunks = len(df_scaled) // chunk_size + 1\n",
    "\n",
    "X_series_list, y_series_list = [], []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = min((i + 1) * chunk_size, len(df_scaled))\n",
    "    df_chunk = df_scaled.iloc[start_idx:end_idx]\n",
    "    X_chunk, y_chunk = create_time_series(df_chunk, window_size, step)\n",
    "    X_series_list.append(X_chunk)\n",
    "    y_series_list.append(y_chunk)\n",
    "\n",
    "# Combinar todos los chunks\n",
    "X_series = np.vstack(X_series_list)\n",
    "y_series = np.concatenate(y_series_list)\n",
    "\n",
    "# Verificar dimensiones de los datos\n",
    "print(f\"Dimensiones de X_series: {X_series.shape}\")\n",
    "print(f\"Dimensiones de y_series: {y_series.shape}\")\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_series, y_series, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)  # Aplanar las series temporales\n",
    "model.fit(X_train_reshaped, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)  # Aplanar las series temporales\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Cargar los nuevos datos\n",
    "nuevos_datos = pd.read_csv('055_Cin_Flex_Dom.xlsx - Serie 1.csv')\n",
    "\n",
    "# Renombrar las columnas del CSV para que coincidan con las utilizadas en el modelo\n",
    "nuevos_datos.columns = ['Id_ejercicio', 'Num_Serie', 'Num_repeticion', 'Fase', 'Tiempo', 'Posicion', 'Fuerza', 'Velocidad', 'Trig', 'Nota']\n",
    "\n",
    "# Seleccionar solo las columnas relevantes para el modelo\n",
    "nuevos_datos = nuevos_datos[['Id_ejercicio', 'Num_Serie', 'Num_repeticion', 'Tiempo', 'Fuerza', 'Posicion', 'Velocidad', 'Trig']]\n",
    "\n",
    "# Preprocesar los nuevos datos de manera similar a los datos de entrenamiento\n",
    "nuevos_datos_scaled = scaler.transform(nuevos_datos)\n",
    "\n",
    "# Crear DataFrame escalado para nuevos datos\n",
    "df_nuevos_scaled = pd.DataFrame(nuevos_datos_scaled, columns=nuevos_datos.columns)\n",
    "\n",
    "# Crear series temporales para los nuevos datos\n",
    "X_nuevos_series, _ = create_time_series(df_nuevos_scaled, window_size, step)\n",
    "\n",
    "# Verificar dimensiones de los nuevos datos\n",
    "print(f\"Dimensiones de X_nuevos_series: {X_nuevos_series.shape}\")\n",
    "\n",
    "# Realizar predicciones\n",
    "X_nuevos_series_reshaped = X_nuevos_series.reshape(X_nuevos_series.shape[0], -1)  # Aplanar las series temporales\n",
    "predicciones = model.predict(X_nuevos_series_reshaped)\n",
    "\n",
    "# Transformar predicciones a nombres de ejercicios\n",
    "nombres_ejercicios = le.inverse_transform(predicciones)\n",
    "\n",
    "# Determinar el nombre del ejercicio más frecuente en las predicciones\n",
    "nombre_ejercicio_final = pd.Series(nombres_ejercicios).mode()[0]\n",
    "\n",
    "# Crear un DataFrame con solo el nombre del ejercicio final\n",
    "df_resultado = pd.DataFrame([nombre_ejercicio_final], columns=['NombreEjercicio'])\n",
    "\n",
    "print(df_resultado)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
